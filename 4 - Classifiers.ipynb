{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "RS = sum(list(map(ord, 'Dale Boca')))\n",
    "\n",
    "import pandas as pd\n",
    "pd.option_context('display.max_rows', None, 'display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "import numpy as np\n",
    "import os;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparación de datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def dataset_prep(window=3, neutral=True):\n",
    "    \n",
    "    train = pd.read_csv('data/trainset_va.csv', index_col=0)\n",
    "    test  = pd.read_csv('data/testset_va.csv', index_col=0)\n",
    "    \n",
    "    cols1 = ['pos', 'neg', 'neu'] if neutral==True else ['pos', 'neg']\n",
    "    \n",
    "    for col in cols1:\n",
    "        train[col+'w'] = train[col].rolling(window=window).sum()\n",
    "        test[col+'w'] = test[col].rolling(window=window).sum()\n",
    "    \n",
    "    train['exc_ret'] = train['exc_ret'].shift(periods=-1)\n",
    "    test['exc_ret']  = test['exc_ret'].shift(periods=-1)\n",
    "    \n",
    "    train.dropna(axis=0, inplace=True)\n",
    "    test.dropna(axis=0, inplace=True)\n",
    "    \n",
    "    cols2 = [x+'w' for x in cols1]\n",
    "    \n",
    "    X = train[cols2]\n",
    "    y = train.exc_ret\n",
    "    Xt = test[cols2]\n",
    "    yt = test.exc_ret\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    y  = le.fit_transform(y)\n",
    "    yt = le.fit_transform(yt)\n",
    "    \n",
    "    return X, Xt, y, yt    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento de Clasificadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scikitplot.metrics import plot_roc\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "#import lightgbm as lgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#from catboost import CatBoostClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(X, Xt, y, yt):\n",
    "    \n",
    "    #model_name = ['Random Forest', 'XGBoost', 'LightGBM', 'Logistic Regression',\n",
    "    #              'Catboost', 'Support Vector']\n",
    "    model_name = ['Random Forest', 'XGBoost', 'Logistic Regression', 'Support Vector']\n",
    "   \n",
    "    model_init = [RandomForestClassifier(),\n",
    "                  XGBClassifier(),\n",
    "                  #lgb.LGBMClassifier(),\n",
    "                  LogisticRegression(),\n",
    "                  #CatBoostClassifier(),\n",
    "                  SVC(probability=True)\n",
    "                 ]\n",
    "    params1 = {  \n",
    "        \"n_estimators\": st.randint(10,100),    # Number of boosted trees to fit.\n",
    "        \"max_depth\"   : st.randint(2, 25),     # Maximum tree depth for base learners.\n",
    "    }\n",
    "    \n",
    "    params2 = {  \n",
    "        \"n_estimators\": st.randint(10,100),    # Number of boosted trees to fit.\n",
    "        \"max_depth\": st.randint(2, 25),         # Maximum tree depth for base learners.\n",
    "        \"learning_rate\": st.uniform(0.01, 0.5), # Boosting learning rate (xgb’s “eta”)\n",
    "        \"colsample_bytree\": st.beta(10, 1),     # Subsample ratio of columns when constructing each tree.\n",
    "        \"subsample\": st.beta(10, 1),            # Subsample ratio of the training instance.\n",
    "        \"gamma\": st.uniform(0, 10),             # Minimum loss reduction required to make a further partition on a leaf node of the tree.\n",
    "        'reg_alpha': st.uniform(0.05,10),       # L1 regularization term on weights\n",
    "        \"min_child_weight\": st.uniform(1,20),   # Minimum sum of instance weight(hessian) needed in a child.\n",
    "    }\n",
    "    \n",
    "    params3 = {  \n",
    "        \"penalty\"     : ['l1', 'l2'],\n",
    "        \"C\"           : st.uniform(0.1, 10.),\n",
    "    }\n",
    "    \n",
    "    params4 = {}\n",
    "    \n",
    "    params5 = {\n",
    "        \"C\"           : st.uniform(0.1, 10.),\n",
    "        #\"kernel\"      : ['lbf', 'linear']\n",
    "    }\n",
    "    \n",
    "    #model_params = [params1, params2, params2, params3, params4, params5]\n",
    "    model_params = [params1, params2, params3, params5]\n",
    "    \n",
    "    train_scores    = []\n",
    "    test_scores     = []\n",
    "    best_estimators = []\n",
    "    best_parameters = []\n",
    "    \n",
    "    for name, mod, params in zip(model_name, model_init, model_params):\n",
    "        model = mod\n",
    "        kf    = KFold(n_splits=5, shuffle=True, random_state=RS)\n",
    "        rgrid = RandomizedSearchCV(estimator=model, param_distributions=params, cv=kf,\n",
    "                                   scoring='roc_auc', n_iter=50, verbose=1, n_jobs=-1)\n",
    "        rgrid.fit(X, y)\n",
    "        best_estimators.append(rgrid.best_estimator_)\n",
    "        best_parameters.append(rgrid.best_params_)\n",
    "        train_scores.append(rgrid.best_score_)\n",
    "        ppred = rgrid.predict_proba(Xt)\n",
    "        score = roc_auc_score(y_score=ppred[:, 1], y_true=yt)\n",
    "        test_scores.append(score)\n",
    "    \n",
    "    results = pd.DataFrame(\n",
    "        {'Model'      : model_name,\n",
    "         'Train Score': train_scores,\n",
    "         'Test Score' : test_scores,\n",
    "         'Params'     : best_parameters,\n",
    "         'Estimator'  : best_estimators\n",
    "        })\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    1.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    4.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  60 tasks      | elapsed:    1.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    4.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    0.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    4.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    1.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    4.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    0.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    4.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    1.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    4.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=-1)]: Done 124 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    3.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    1.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    4.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=-1)]: Done 124 tasks      | elapsed:    2.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    4.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    1.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    4.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    0.7s finished\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "windows = np.arange(1, 6)\n",
    "neutral = [1, 0]\n",
    "\n",
    "resultado = pd.DataFrame()\n",
    "\n",
    "for win, neu in itertools.product(windows, neutral):\n",
    "    \n",
    "    X, X_test, y, y_test = dataset_prep(window=win, neutral=neu)\n",
    "    \n",
    "    clfs = train_classifier(X, X_test, y, y_test)\n",
    "  \n",
    "    res = pd.DataFrame(\n",
    "    {'Model'      : clfs['Model'],\n",
    "     'Window'     : list(str(win)*clfs.shape[0]),\n",
    "     'Neutral'    : list(str(neu)*clfs.shape[0]),\n",
    "     'Train Score': clfs['Train Score'],\n",
    "     'Test Score' : clfs['Test Score'],\n",
    "     'Params'     : clfs['Params'],\n",
    "     'Estimator'  : clfs['Estimator']\n",
    "    })\n",
    "    \n",
    "    resultado = pd.concat([resultado, res], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Window</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Train Score</th>\n",
       "      <th>Test Score</th>\n",
       "      <th>Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.634764</td>\n",
       "      <td>0.446633</td>\n",
       "      <td>{'max_depth': 21, 'n_estimators': 91}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Support Vector</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.620285</td>\n",
       "      <td>0.525146</td>\n",
       "      <td>{'C': 1.021127977480073}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.620146</td>\n",
       "      <td>0.429916</td>\n",
       "      <td>{'max_depth': 21, 'n_estimators': 17}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.608756</td>\n",
       "      <td>0.502020</td>\n",
       "      <td>{'colsample_bytree': 0.9558007758002638, 'gamma': 0.3592271437338024, 'learning_rate': 0.2347214582414079, 'max_depth': 13, 'min_child_weight': 1.5094203289648025, 'n_estimators': 45, 'reg_alpha': 1.4168590285168114, 'subsample': 0.8460337904893644}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.606338</td>\n",
       "      <td>0.431145</td>\n",
       "      <td>{'max_depth': 7, 'n_estimators': 89}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.605955</td>\n",
       "      <td>0.484263</td>\n",
       "      <td>{'max_depth': 2, 'n_estimators': 15}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.591777</td>\n",
       "      <td>0.403581</td>\n",
       "      <td>{'max_depth': 8, 'n_estimators': 72}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.587454</td>\n",
       "      <td>0.422865</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 12}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.585480</td>\n",
       "      <td>0.419192</td>\n",
       "      <td>{'C': 0.9361762042067422, 'penalty': 'l2'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.583696</td>\n",
       "      <td>0.474367</td>\n",
       "      <td>{'colsample_bytree': 0.9306406209261033, 'gamma': 2.002491473029553, 'learning_rate': 0.49513991006872526, 'max_depth': 11, 'min_child_weight': 5.159915326988246, 'n_estimators': 46, 'reg_alpha': 2.8400398934563573, 'subsample': 0.9487864294110588}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.583302</td>\n",
       "      <td>0.398072</td>\n",
       "      <td>{'C': 0.8990641488914585, 'penalty': 'l2'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.577249</td>\n",
       "      <td>0.470386</td>\n",
       "      <td>{'colsample_bytree': 0.805330407965493, 'gamma': 4.040312025309293, 'learning_rate': 0.08112228679022336, 'max_depth': 20, 'min_child_weight': 14.37377790009133, 'n_estimators': 76, 'reg_alpha': 0.6203412739442837, 'subsample': 0.9901787875779942}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Support Vector</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.573453</td>\n",
       "      <td>0.551383</td>\n",
       "      <td>{'C': 0.2993267523311415}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.571987</td>\n",
       "      <td>0.421717</td>\n",
       "      <td>{'C': 4.266154419608567, 'penalty': 'l2'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.571486</td>\n",
       "      <td>0.361660</td>\n",
       "      <td>{'C': 0.2142333648845273, 'penalty': 'l1'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.562937</td>\n",
       "      <td>0.473718</td>\n",
       "      <td>{'colsample_bytree': 0.8113413450062855, 'gamma': 1.568849186614616, 'learning_rate': 0.2648991015038754, 'max_depth': 2, 'min_child_weight': 19.563501299033152, 'n_estimators': 12, 'reg_alpha': 1.612611682933477, 'subsample': 0.8640444197761171}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.560391</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>{'colsample_bytree': 0.8621701544753992, 'gamma': 2.049916958831216, 'learning_rate': 0.34894706429768646, 'max_depth': 8, 'min_child_weight': 10.94834020190395, 'n_estimators': 89, 'reg_alpha': 2.8646304018964828, 'subsample': 0.99779113310699}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.556132</td>\n",
       "      <td>0.386199</td>\n",
       "      <td>{'C': 7.898081911098933, 'penalty': 'l2'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.555783</td>\n",
       "      <td>0.470034</td>\n",
       "      <td>{'colsample_bytree': 0.992192178802174, 'gamma': 1.2228805811717935, 'learning_rate': 0.25247819235266256, 'max_depth': 14, 'min_child_weight': 12.426959880233916, 'n_estimators': 77, 'reg_alpha': 4.1792652583124115, 'subsample': 0.977425296857233}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.553475</td>\n",
       "      <td>0.464751</td>\n",
       "      <td>{'max_depth': 4, 'n_estimators': 17}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.552871</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>{'max_depth': 15, 'n_estimators': 14}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Support Vector</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.552166</td>\n",
       "      <td>0.512702</td>\n",
       "      <td>{'C': 7.234485589371243}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.550645</td>\n",
       "      <td>0.481423</td>\n",
       "      <td>{'max_depth': 4, 'n_estimators': 25}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Support Vector</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.542609</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>{'C': 0.394928829145028}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Support Vector</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.542340</td>\n",
       "      <td>0.511194</td>\n",
       "      <td>{'C': 1.4482184719859037}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.542241</td>\n",
       "      <td>0.442837</td>\n",
       "      <td>{'C': 0.33036800242117403, 'penalty': 'l1'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.539827</td>\n",
       "      <td>0.372485</td>\n",
       "      <td>{'C': 0.1506119649439807, 'penalty': 'l1'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.536662</td>\n",
       "      <td>0.493083</td>\n",
       "      <td>{'colsample_bytree': 0.8859011681167236, 'gamma': 0.08021339731271726, 'learning_rate': 0.36980390095277016, 'max_depth': 19, 'min_child_weight': 20.042371445133057, 'n_estimators': 28, 'reg_alpha': 6.1715598151194575, 'subsample': 0.9308607635431082}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.535758</td>\n",
       "      <td>0.380759</td>\n",
       "      <td>{'C': 0.587558989120832, 'penalty': 'l1'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.521334</td>\n",
       "      <td>0.528898</td>\n",
       "      <td>{'colsample_bytree': 0.9595369722608542, 'gamma': 2.429140622768587, 'learning_rate': 0.12158746740922576, 'max_depth': 22, 'min_child_weight': 3.8097453940411787, 'n_estimators': 70, 'reg_alpha': 1.8339799235172893, 'subsample': 0.9461354722898259}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.519964</td>\n",
       "      <td>0.354875</td>\n",
       "      <td>{'C': 2.254631686633035, 'penalty': 'l1'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.516470</td>\n",
       "      <td>0.496542</td>\n",
       "      <td>{'max_depth': 2, 'n_estimators': 26}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.512678</td>\n",
       "      <td>0.479359</td>\n",
       "      <td>{'colsample_bytree': 0.8174505490910872, 'gamma': 0.12985352022794938, 'learning_rate': 0.16624273241864718, 'max_depth': 9, 'min_child_weight': 14.010089147035579, 'n_estimators': 47, 'reg_alpha': 2.309642480193653, 'subsample': 0.8952006470318112}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.510129</td>\n",
       "      <td>0.473814</td>\n",
       "      <td>{'colsample_bytree': 0.8495534310482661, 'gamma': 0.0037609649460157435, 'learning_rate': 0.4792747319365345, 'max_depth': 10, 'min_child_weight': 4.369159408942435, 'n_estimators': 46, 'reg_alpha': 2.5919491454762706, 'subsample': 0.8866813618671141}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Support Vector</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.488048</td>\n",
       "      <td>0.575758</td>\n",
       "      <td>{'C': 0.5951211620208373}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Support Vector</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.486268</td>\n",
       "      <td>0.495883</td>\n",
       "      <td>{'C': 1.7017945994779504}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Support Vector</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.478355</td>\n",
       "      <td>0.524770</td>\n",
       "      <td>{'C': 5.3057539547410935}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.471847</td>\n",
       "      <td>0.369959</td>\n",
       "      <td>{'C': 0.2947232672363397, 'penalty': 'l1'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Support Vector</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.466244</td>\n",
       "      <td>0.563300</td>\n",
       "      <td>{'C': 1.426231979205962}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Support Vector</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.457542</td>\n",
       "      <td>0.491563</td>\n",
       "      <td>{'C': 0.4959944948241578}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model Window Neutral  Train Score  Test Score  \\\n",
       "0  Random Forest        4      1       0.634764     0.446633     \n",
       "3  Support Vector       2      1       0.620285     0.525146     \n",
       "0  Random Forest        2      1       0.620146     0.429916     \n",
       "1  XGBoost              4      1       0.608756     0.502020     \n",
       "0  Random Forest        4      0       0.606338     0.431145     \n",
       "0  Random Forest        2      0       0.605955     0.484263     \n",
       "0  Random Forest        5      1       0.591777     0.403581     \n",
       "0  Random Forest        5      0       0.587454     0.422865     \n",
       "2  Logistic Regression  4      1       0.585480     0.419192     \n",
       "1  XGBoost              2      1       0.583696     0.474367     \n",
       "2  Logistic Regression  5      1       0.583302     0.398072     \n",
       "1  XGBoost              5      1       0.577249     0.470386     \n",
       "3  Support Vector       3      1       0.573453     0.551383     \n",
       "2  Logistic Regression  4      0       0.571987     0.421717     \n",
       "2  Logistic Regression  3      1       0.571486     0.361660     \n",
       "1  XGBoost              2      0       0.562937     0.473718     \n",
       "1  XGBoost              5      0       0.560391     0.484848     \n",
       "2  Logistic Regression  3      0       0.556132     0.386199     \n",
       "1  XGBoost              4      0       0.555783     0.470034     \n",
       "0  Random Forest        1      0       0.553475     0.464751     \n",
       "0  Random Forest        3      1       0.552871     0.477273     \n",
       "3  Support Vector       1      1       0.552166     0.512702     \n",
       "0  Random Forest        1      1       0.550645     0.481423     \n",
       "3  Support Vector       4      1       0.542609     0.454545     \n",
       "3  Support Vector       2      0       0.542340     0.511194     \n",
       "2  Logistic Regression  5      0       0.542241     0.442837     \n",
       "2  Logistic Regression  2      1       0.539827     0.372485     \n",
       "1  XGBoost              3      1       0.536662     0.493083     \n",
       "2  Logistic Regression  2      0       0.535758     0.380759     \n",
       "1  XGBoost              1      0       0.521334     0.528898     \n",
       "2  Logistic Regression  1      0       0.519964     0.354875     \n",
       "0  Random Forest        3      0       0.516470     0.496542     \n",
       "1  XGBoost              1      1       0.512678     0.479359     \n",
       "1  XGBoost              3      0       0.510129     0.473814     \n",
       "3  Support Vector       5      0       0.488048     0.575758     \n",
       "3  Support Vector       3      0       0.486268     0.495883     \n",
       "3  Support Vector       1      0       0.478355     0.524770     \n",
       "2  Logistic Regression  1      1       0.471847     0.369959     \n",
       "3  Support Vector       4      0       0.466244     0.563300     \n",
       "3  Support Vector       5      1       0.457542     0.491563     \n",
       "\n",
       "                                                                                                                                                                                                                                                        Params  \n",
       "0  {'max_depth': 21, 'n_estimators': 91}                                                                                                                                                                                                                        \n",
       "3  {'C': 1.021127977480073}                                                                                                                                                                                                                                     \n",
       "0  {'max_depth': 21, 'n_estimators': 17}                                                                                                                                                                                                                        \n",
       "1  {'colsample_bytree': 0.9558007758002638, 'gamma': 0.3592271437338024, 'learning_rate': 0.2347214582414079, 'max_depth': 13, 'min_child_weight': 1.5094203289648025, 'n_estimators': 45, 'reg_alpha': 1.4168590285168114, 'subsample': 0.8460337904893644}    \n",
       "0  {'max_depth': 7, 'n_estimators': 89}                                                                                                                                                                                                                         \n",
       "0  {'max_depth': 2, 'n_estimators': 15}                                                                                                                                                                                                                         \n",
       "0  {'max_depth': 8, 'n_estimators': 72}                                                                                                                                                                                                                         \n",
       "0  {'max_depth': 15, 'n_estimators': 12}                                                                                                                                                                                                                        \n",
       "2  {'C': 0.9361762042067422, 'penalty': 'l2'}                                                                                                                                                                                                                   \n",
       "1  {'colsample_bytree': 0.9306406209261033, 'gamma': 2.002491473029553, 'learning_rate': 0.49513991006872526, 'max_depth': 11, 'min_child_weight': 5.159915326988246, 'n_estimators': 46, 'reg_alpha': 2.8400398934563573, 'subsample': 0.9487864294110588}     \n",
       "2  {'C': 0.8990641488914585, 'penalty': 'l2'}                                                                                                                                                                                                                   \n",
       "1  {'colsample_bytree': 0.805330407965493, 'gamma': 4.040312025309293, 'learning_rate': 0.08112228679022336, 'max_depth': 20, 'min_child_weight': 14.37377790009133, 'n_estimators': 76, 'reg_alpha': 0.6203412739442837, 'subsample': 0.9901787875779942}      \n",
       "3  {'C': 0.2993267523311415}                                                                                                                                                                                                                                    \n",
       "2  {'C': 4.266154419608567, 'penalty': 'l2'}                                                                                                                                                                                                                    \n",
       "2  {'C': 0.2142333648845273, 'penalty': 'l1'}                                                                                                                                                                                                                   \n",
       "1  {'colsample_bytree': 0.8113413450062855, 'gamma': 1.568849186614616, 'learning_rate': 0.2648991015038754, 'max_depth': 2, 'min_child_weight': 19.563501299033152, 'n_estimators': 12, 'reg_alpha': 1.612611682933477, 'subsample': 0.8640444197761171}       \n",
       "1  {'colsample_bytree': 0.8621701544753992, 'gamma': 2.049916958831216, 'learning_rate': 0.34894706429768646, 'max_depth': 8, 'min_child_weight': 10.94834020190395, 'n_estimators': 89, 'reg_alpha': 2.8646304018964828, 'subsample': 0.99779113310699}        \n",
       "2  {'C': 7.898081911098933, 'penalty': 'l2'}                                                                                                                                                                                                                    \n",
       "1  {'colsample_bytree': 0.992192178802174, 'gamma': 1.2228805811717935, 'learning_rate': 0.25247819235266256, 'max_depth': 14, 'min_child_weight': 12.426959880233916, 'n_estimators': 77, 'reg_alpha': 4.1792652583124115, 'subsample': 0.977425296857233}     \n",
       "0  {'max_depth': 4, 'n_estimators': 17}                                                                                                                                                                                                                         \n",
       "0  {'max_depth': 15, 'n_estimators': 14}                                                                                                                                                                                                                        \n",
       "3  {'C': 7.234485589371243}                                                                                                                                                                                                                                     \n",
       "0  {'max_depth': 4, 'n_estimators': 25}                                                                                                                                                                                                                         \n",
       "3  {'C': 0.394928829145028}                                                                                                                                                                                                                                     \n",
       "3  {'C': 1.4482184719859037}                                                                                                                                                                                                                                    \n",
       "2  {'C': 0.33036800242117403, 'penalty': 'l1'}                                                                                                                                                                                                                  \n",
       "2  {'C': 0.1506119649439807, 'penalty': 'l1'}                                                                                                                                                                                                                   \n",
       "1  {'colsample_bytree': 0.8859011681167236, 'gamma': 0.08021339731271726, 'learning_rate': 0.36980390095277016, 'max_depth': 19, 'min_child_weight': 20.042371445133057, 'n_estimators': 28, 'reg_alpha': 6.1715598151194575, 'subsample': 0.9308607635431082}  \n",
       "2  {'C': 0.587558989120832, 'penalty': 'l1'}                                                                                                                                                                                                                    \n",
       "1  {'colsample_bytree': 0.9595369722608542, 'gamma': 2.429140622768587, 'learning_rate': 0.12158746740922576, 'max_depth': 22, 'min_child_weight': 3.8097453940411787, 'n_estimators': 70, 'reg_alpha': 1.8339799235172893, 'subsample': 0.9461354722898259}    \n",
       "2  {'C': 2.254631686633035, 'penalty': 'l1'}                                                                                                                                                                                                                    \n",
       "0  {'max_depth': 2, 'n_estimators': 26}                                                                                                                                                                                                                         \n",
       "1  {'colsample_bytree': 0.8174505490910872, 'gamma': 0.12985352022794938, 'learning_rate': 0.16624273241864718, 'max_depth': 9, 'min_child_weight': 14.010089147035579, 'n_estimators': 47, 'reg_alpha': 2.309642480193653, 'subsample': 0.8952006470318112}    \n",
       "1  {'colsample_bytree': 0.8495534310482661, 'gamma': 0.0037609649460157435, 'learning_rate': 0.4792747319365345, 'max_depth': 10, 'min_child_weight': 4.369159408942435, 'n_estimators': 46, 'reg_alpha': 2.5919491454762706, 'subsample': 0.8866813618671141}  \n",
       "3  {'C': 0.5951211620208373}                                                                                                                                                                                                                                    \n",
       "3  {'C': 1.7017945994779504}                                                                                                                                                                                                                                    \n",
       "3  {'C': 5.3057539547410935}                                                                                                                                                                                                                                    \n",
       "2  {'C': 0.2947232672363397, 'penalty': 'l1'}                                                                                                                                                                                                                   \n",
       "3  {'C': 1.426231979205962}                                                                                                                                                                                                                                     \n",
       "3  {'C': 0.4959944948241578}                                                                                                                                                                                                                                    "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado.sort_values(by='Train Score', ascending=False).iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
